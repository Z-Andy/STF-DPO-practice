import os
from paths import HF_HOME, FINAL_TEST_IMG_DIR, FINAL_TEST_CSV_PATH

# ================= é…ç½®ç¯å¢ƒå˜é‡ (å¿…é¡»åœ¨ import torch ä¹‹å‰) =================
CACHE_DIR = HF_HOME
os.environ["HF_HOME"] = CACHE_DIR
os.environ["TORCH_HOME"] = CACHE_DIR
# =========================================================================

import torch
import pandas as pd
from PIL import Image
from transformers import AutoModelForCausalLM
from scipy.stats import spearmanr, pearsonr
from tqdm import tqdm
import numpy as np

# è·¯å¾„é…ç½®
IMG_DIR = FINAL_TEST_IMG_DIR
CSV_PATH = FINAL_TEST_CSV_PATH

def clean_id(val):
    """ç¨³å¥çš„ ID æ¸…æ´—å‡½æ•°"""
    s = str(val).strip()
    try:
        # å¤„ç† 1001.0 -> 1001
        return str(int(float(s)))
    except:
        # å¦‚æœè‡ªå¸¦åç¼€ï¼Œå»æ‰å®ƒ (åé¢ç»Ÿä¸€åŠ )
        if s.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG')):
            return os.path.splitext(s)[0]
        return s

def main():
    print(f"ğŸš€ æ­£åœ¨åŠ è½½ Q-Align æ¨¡å‹ (OneAlign)...")
    
    try:
        # âš ï¸ trust_remote_code=True ä¼šè‡ªåŠ¨ä¸‹è½½ q-future/one-align çš„ä»£ç 
        # å®ƒä¾èµ– transformers 4.36+ å’Œ flash-attn
        model = AutoModelForCausalLM.from_pretrained(
            "q-future/one-align", 
            trust_remote_code=True, 
            torch_dtype=torch.float16, 
            device_map="auto",
            cache_dir=CACHE_DIR
        )
    except Exception as e:
        print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥: pip list | grep transformers æ˜¯å¦ä¸º 4.36.2")
        return

    # è¯»å–å¹¶å¤„ç† CSV
    if not os.path.exists(CSV_PATH):
        print(f"âŒ æ‰¾ä¸åˆ° CSV: {CSV_PATH}")
        return
    
    df = pd.read_csv(CSV_PATH)
    df['ID'] = df['ID'].apply(clean_id)
    
    gt_scores = []
    pred_scores = []
    valid_count = 0

    print(f"ğŸ“Š å¼€å§‹æ¨ç† {len(df)} å¼ å›¾ç‰‡ (ç¾å­¦è¯„åˆ†ä»»åŠ¡)...")

    for _, row in tqdm(df.iterrows(), total=len(df)):
        img_id = row['ID']
        # å°è¯•åŒ¹é… jpg å’Œ JPG
        img_path = os.path.join(IMG_DIR, f"{img_id}.jpg")
        if not os.path.exists(img_path):
            img_path = os.path.join(IMG_DIR, f"{img_id}.JPG")
        
        if not os.path.exists(img_path):
            # print(f"âš ï¸ å›¾ç‰‡æœªæ‰¾åˆ°: {img_id}") # å¤ªå¤šå¯ä»¥æ³¨é‡Šæ‰
            continue

        try:
            image = Image.open(img_path).convert("RGB")
            
            with torch.no_grad():
                # Q-Align å®˜æ–¹ API: task_="aesthetics"
                # è¿”å›å€¼é€šå¸¸æ˜¯ä¸€ä¸ª list æˆ– tensor
                score = model.score([image], task_="aesthetics", input_="image")
                
                # æå–æ ‡é‡å€¼
                if isinstance(score, list):
                    val = float(score[0])
                elif isinstance(score, torch.Tensor):
                    val = score.item() if score.numel() == 1 else score[0].item()
                else:
                    val = float(score)

            pred_scores.append(val)
            gt_scores.append(float(row['score']))
            valid_count += 1
            
        except Exception as e:
            print(f"âŒ å¤„ç†å‡ºé”™ ID {img_id}: {e}")

    # è®¡ç®—ç»“æœ
    if valid_count > 1:
        srcc, _ = spearmanr(gt_scores, pred_scores)
        plcc, _ = pearsonr(gt_scores, pred_scores)
        
        print("\n" + "="*50)
        print(f"ğŸ† Q-Align (OneAlign) Benchmark Result")
        print(f"æœ‰æ•ˆæ ·æœ¬: {valid_count}/{len(df)}")
        print(f"SRCC: {srcc:.4f}")
        print(f"PLCC: {plcc:.4f}")
        print("="*50)
    else:
        print("\nâŒ æœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡ã€‚")

if __name__ == "__main__":
    main()